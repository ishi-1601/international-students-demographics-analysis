{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75baee85",
   "metadata": {},
   "source": [
    "# ðŸŽ“ International Students Demographics Cleanup (Reconstructed)\n",
    "\n",
    "This notebook **reconstructs** the data cleaning workflow for the *International Students Demographics* project.\n",
    "Because the original CSVs are not included, we **simulate small sample datasets** that mimic the structure of the six sources:\n",
    "`academic.csv`, `academic_detail.csv`, `field_of_study.csv`, `origin.csv`, `source_of_fund.csv`, and `status.csv`.\n",
    "\n",
    "You can run this notebook end-to-end to see how the pipeline works:\n",
    "1) generate data â†’ 2) load â†’ 3) validate â†’ 4) clean â†’ 5) export to Excel â†’ 6) quick plots."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2577e49e",
   "metadata": {},
   "source": [
    "## 1. Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889636b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path('data')\n",
    "DATA_DIR.mkdir(exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdeb3405",
   "metadata": {},
   "source": [
    "## 2. Generate Simulated Datasets (if originals are missing)\n",
    "The shapes and columns are inspired by the original sources, with small random values for demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc59d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Academic overview\n",
    "df1 = pd.DataFrame({\n",
    "    'year': ['2018/19','2019/20','2020/21','2021/22','2022/23'],\n",
    "    'students': [1095299, 1075496, 914095, 948519, 1057188],\n",
    "    'us_students': [19828000, 19720000, 19744000, 20327000, 18961280],\n",
    "    'undergraduate': [431930, 419321, 359787, 344532, 347602],\n",
    "    'graduate': [377943, 374435, 329272, 385097, 467027],\n",
    "    'non_degree': [62341, 58201, 21151, 34131, 43766],\n",
    "    'opt': [223085, 223539, 203885, 184759, 198793]\n",
    "})\n",
    "\n",
    "# Academic detail\n",
    "df2 = pd.DataFrame({\n",
    "    'year': ['2019/20','2019/20','2022/23','2022/23'],\n",
    "    'academic_type': ['Undergraduate','Graduate','Non-Degree','OPT'],\n",
    "    'academic_level': [\"Bachelor's\",\"Master's\",\"Intensive English\",\"OPT\"],\n",
    "    'students': [177381, 110857, 10801, 198793]\n",
    "})\n",
    "\n",
    "# Field of study\n",
    "df3 = pd.DataFrame({\n",
    "    'year': ['2019/20','2019/20','2022/23','2022/23'],\n",
    "    'field_of_study': ['Business and Management','Engineering','Computer and Information Sciences','Social Sciences'],\n",
    "    'major': ['Business and Management','Engineering','Computer and Information Sciences','Social Sciences'],\n",
    "    'students': [101360.0, 146000.0, np.nan, 53998.0]  # include a NaN to demonstrate fillna\n",
    "})\n",
    "\n",
    "# Origin (region, country, academic type)\n",
    "df4 = pd.DataFrame({\n",
    "    'year': ['2022/23']*5,\n",
    "    'origin_region': ['East Asia','South Asia','Middle East','Europe','Latin America'],\n",
    "    'origin': ['China','India','Saudi Arabia','Germany','Brazil'],\n",
    "    'academic_type': ['Undergraduate','Graduate','Graduate','Undergraduate','Non-Degree'],\n",
    "    'students': [150000, 200000, 38000, 25000, 12000]\n",
    "})\n",
    "\n",
    "# Source of funds\n",
    "df5 = pd.DataFrame({\n",
    "    'year': ['2022/23']*5,\n",
    "    'academic_type': ['Undergraduate','Undergraduate','Graduate','Graduate','OPT'],\n",
    "    'source_type': ['International','U.S.','International','U.S.','U.S.'],\n",
    "    'source_of_fund': ['Personal/Family','U.S. Govt','Foreign Govt/Univ','U.S. Univ','Current Employment'],\n",
    "    'students': [201578, 749, 9742, 12450, 198793]\n",
    "})\n",
    "\n",
    "# Status (gender, marital, visa, study load)\n",
    "df6 = pd.DataFrame({\n",
    "    'year': [str(y) for y in range(2008, 2013)],\n",
    "    'female': np.random.randint(250000, 400000, 5),\n",
    "    'male': np.random.randint(300000, 500000, 5),\n",
    "    'single': np.random.randint(500000, 800000, 5),\n",
    "    'married': np.random.randint(60000, 100000, 5),\n",
    "    'full_time': np.random.randint(700000, 1000000, 5),\n",
    "    'part_time': np.random.randint(40000, 80000, 5),\n",
    "    'visa_f': np.random.randint(600000, 900000, 5),\n",
    "    'visa_j': np.random.randint(300, 800, 5),\n",
    "    'visa_other': np.random.randint(20, 80, 5)\n",
    "})\n",
    "\n",
    "# Save to CSV so the rest of the notebook behaves like the original workflow\n",
    "df1.to_csv(DATA_DIR / 'academic.csv', index=False)\n",
    "df2.to_csv(DATA_DIR / 'academic_detail.csv', index=False)\n",
    "df3.to_csv(DATA_DIR / 'field_of_study.csv', index=False)\n",
    "df4.to_csv(DATA_DIR / 'origin.csv', index=False)\n",
    "df5.to_csv(DATA_DIR / 'source_of_fund.csv', index=False)\n",
    "df6.to_csv(DATA_DIR / 'status.csv', index=False)\n",
    "\n",
    "print('Simulated CSVs written to', DATA_DIR.resolve())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760ef775",
   "metadata": {},
   "source": [
    "## 3. Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56adef0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(DATA_DIR / 'academic.csv')\n",
    "df2 = pd.read_csv(DATA_DIR / 'academic_detail.csv')\n",
    "df3 = pd.read_csv(DATA_DIR / 'field_of_study.csv')\n",
    "df4 = pd.read_csv(DATA_DIR / 'origin.csv')\n",
    "df5 = pd.read_csv(DATA_DIR / 'source_of_fund.csv')\n",
    "df6 = pd.read_csv(DATA_DIR / 'status.csv')\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a176c7d4",
   "metadata": {},
   "source": [
    "## 4. Data Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2b599e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Null checks\n",
    "null_summary = {\n",
    "    'df1_academic': df1.isnull().any().to_dict(),\n",
    "    'df2_academic_detail': df2.isnull().any().to_dict(),\n",
    "    'df3_field_of_study': df3.isnull().any().to_dict(),\n",
    "    'df4_origin': df4.isnull().any().to_dict(),\n",
    "    'df5_source_of_fund': df5.isnull().any().to_dict(),\n",
    "    'df6_status': df6.isnull().any().to_dict(),\n",
    "}\n",
    "null_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567321b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicates check (row-level)\n",
    "{\n",
    " 'df1_dupes': int(df1.duplicated().sum()),\n",
    " 'df2_dupes': int(df2.duplicated().sum()),\n",
    " 'df3_dupes': int(df3.duplicated().sum()),\n",
    " 'df4_dupes': int(df4.duplicated().sum()),\n",
    " 'df5_dupes': int(df5.duplicated().sum()),\n",
    " 'df6_dupes': int(df6.duplicated().sum()),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e065de",
   "metadata": {},
   "source": [
    "## 5. Cleaning Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bc2027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NA for numeric fields where appropriate\n",
    "for col in ['us_students','undergraduate','graduate','non_degree','opt']:\n",
    "    if col in df1.columns:\n",
    "        df1[col] = df1[col].fillna(0)\n",
    "\n",
    "if 'students' in df3.columns:\n",
    "    df3['students'] = df3['students'].fillna(0)\n",
    "\n",
    "# Drop duplicates\n",
    "df1 = df1.drop_duplicates()\n",
    "df2 = df2.drop_duplicates()\n",
    "df3 = df3.drop_duplicates()\n",
    "df4 = df4.drop_duplicates()\n",
    "df5 = df5.drop_duplicates()\n",
    "df6 = df6.drop_duplicates()\n",
    "\n",
    "print('Cleaning complete.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824412ad",
   "metadata": {},
   "source": [
    "## 6. Validation After Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f38555b",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    " 'df1_null_any': df1.isnull().any().to_dict(),\n",
    " 'df3_null_any': df3.isnull().any().to_dict(),\n",
    " 'df1_rows': len(df1),\n",
    " 'df2_rows': len(df2),\n",
    " 'df3_rows': len(df3),\n",
    " 'df4_rows': len(df4),\n",
    " 'df5_rows': len(df5),\n",
    " 'df6_rows': len(df6),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6bf197",
   "metadata": {},
   "source": [
    "## 7. Export Cleaned Data to a Single Excel Workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b11ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = Path('output_file.xlsx')\n",
    "with pd.ExcelWriter(output_path) as writer:\n",
    "    df1.to_excel(writer, sheet_name='academic', index=False)\n",
    "    df2.to_excel(writer, sheet_name='academic_detail', index=False)\n",
    "    df3.to_excel(writer, sheet_name='field_of_study', index=False)\n",
    "    df4.to_excel(writer, sheet_name='origin', index=False)\n",
    "    df5.to_excel(writer, sheet_name='source_of_fund', index=False)\n",
    "    df6.to_excel(writer, sheet_name='status', index=False)\n",
    "output_path.resolve()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a86e76",
   "metadata": {},
   "source": [
    "## 8. Quick Sanity Plots (Matplotlib)\n",
    "Simple line charts to visually sanity-check a few time-based columns.\n",
    "*(Note: For portfolio clarity, we avoid styling and keep one chart per cell.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60bdcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "if 'year' in df1.columns and 'students' in df1.columns:\n",
    "    # Attempt to convert 'year' like '2022/23' to numeric start year\n",
    "    year_start = df1['year'].astype(str).str.slice(0,4).astype(int)\n",
    "    plt.plot(year_start, df1['students'])\n",
    "    plt.title('Total International Students Over Time')\n",
    "    plt.xlabel('Year (start)')\n",
    "    plt.ylabel('Students')\n",
    "    plt.show()\n",
    "else:\n",
    "    print('df1 missing expected columns for plotting.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad7fedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "if 'year' in df6.columns and 'female' in df6.columns and 'male' in df6.columns:\n",
    "    x = pd.to_numeric(df6['year'], errors='coerce')\n",
    "    plt.plot(x, df6['female'], label='Female')\n",
    "    plt.plot(x, df6['male'], label='Male')\n",
    "    plt.title('Gender Distribution Over Years (Simulated)')\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Count')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "else:\n",
    "    print('df6 missing expected columns for plotting.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d6772a",
   "metadata": {},
   "source": [
    "## 9. Result & Conclusion\n",
    "- All six datasets were **cleaned** (missing values handled, duplicates removed) and **validated**.\n",
    "- A combined Excel workbook `output_file.xlsx` with six sheets was generated for downstream BI use.\n",
    "- This reconstruction mirrors the original workflow and is suitable for **portfolio demonstration**.\n",
    "\n",
    "**Next steps:** Connect the cleaned workbook to Power BI, add slicers for year/academic type/field of study, and design visuals for visa type, gender, marital status, employment, and funding sources."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
